{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\SoumyaRoy\\\\Downloads'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>carrier</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "      <th>churn_likeliness</th>\n",
       "      <th>clf_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2750</td>\n",
       "      <td>att tmobile</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0</td>\n",
       "      <td>@tmobile @att glad to hear working out for you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2765</td>\n",
       "      <td>att tmobile</td>\n",
       "      <td>neu</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>@att @tmobile r u a virgin or do you just play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>att tmobile</td>\n",
       "      <td>neu</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>oh gawd don t do that they have no tower atm n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2892</td>\n",
       "      <td>att tmobile</td>\n",
       "      <td>neu</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>on the same note my dad switched his phone int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2897</td>\n",
       "      <td>att tmobile</td>\n",
       "      <td>neu</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>switched to @tmobile from @att and i am just b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      carrier sentiment  polarity  churn_likeliness  \\\n",
       "0        2750  att tmobile       pos    0.4375                 0   \n",
       "1        2765  att tmobile       neu    0.0000                 0   \n",
       "2        2804  att tmobile       neu    0.0000                 1   \n",
       "3        2892  att tmobile       neu    0.0000                 1   \n",
       "4        2897  att tmobile       neu    0.0000                 1   \n",
       "\n",
       "                                            clf_text  \n",
       "0  @tmobile @att glad to hear working out for you...  \n",
       "1  @att @tmobile r u a virgin or do you just play...  \n",
       "2  oh gawd don t do that they have no tower atm n...  \n",
       "3  on the same note my dad switched his phone int...  \n",
       "4  switched to @tmobile from @att and i am just b...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('C:/Users/SoumyaRoy/Downloads')\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"TrainingData_labels.csv\", encoding ='latin1')\n",
    "df.columns\n",
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    571\n",
       "1    224\n",
       "Name: churn_likeliness, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['churn_likeliness'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(795, 6)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clf_text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cleaning text\n",
    "import time\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "start_time = time.time()                                    \n",
    "clean_text = []\n",
    "for text in df['question']:\n",
    "    words = regexp_tokenize(text.lower(), r'[A-Za-z]+')\n",
    "    words = [w for w in words if len(w)>1 and w not in stopwords.words('english')]\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "    clean_text.append(' '.join(words))\n",
    "print('Elapsed clock time: ', (time.time() - start_time)/60, ' minutes')\n",
    "\n",
    "len(clean_text)\n",
    "df['clean_text'] = clean_text\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation and encode label\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = \\\n",
    "    train_test_split(df['clf_text'], df['churn_likeliness'], \\\n",
    "    test_size=0.2, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the y value to numeric\n",
    "# encoder = LabelEncoder()\n",
    "# train_y = encoder.fit_transform(train_y)\n",
    "# valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the x value to numeric\n",
    "#Text vectorization: Create count, TF-IDF, and n-gram vectorizers\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# n-gram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', \\\n",
    "    ngram_range=(1,5), max_features=5000)\n",
    "tfidf_vect_ngram.fit(df['clf_text'])\n",
    "xtrain_tfidf_ngram = tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram = tfidf_vect_ngram.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Models and Success metrics\n",
    "  \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "  \n",
    "def model(classifier, train_vector, valid_vector):\n",
    "    classifier.fit(train_vector, train_y)  \n",
    "    predict_y = classifier.predict(valid_vector)\n",
    "    accuracy = accuracy_score(valid_y, predict_y)\n",
    "    precision = precision_score(valid_y, predict_y,labels=[0,1,2,3,4,5,6],average=None)\n",
    "    recall = recall_score(valid_y, predict_y,labels=[0,1,2,3,4,5,6],average=None)\n",
    "    conf_matrix = confusion_matrix(valid_y, classifier.predict(valid_vector))\n",
    "    print('\\nAccuracy_score: {:.3f}'.format(accuracy ))\n",
    "    print('precision_score: {:.3f}'.format(precision.mean()))\n",
    "    print('recall_score: {:.3f}'.format(recall.mean()))\n",
    "    print('\\nconfusion_matrix: \\n')\n",
    "    \n",
    "    print(confusion_matrix(valid_y, classifier.predict(valid_vector)))\n",
    "    #print(classification_report(valid_y, classifier.predict(valid_vector)))\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBClassifier and Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy_score: 0.698\n",
      "precision_score: 0.206\n",
      "recall_score: 0.157\n",
      "\n",
      "confusion_matrix: \n",
      "\n",
      "[[105   2]\n",
      " [ 46   6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SoumyaRoy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\SoumyaRoy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model(MultinomialNB(), xtrain_tfidf_ngram, xvalid_tfidf_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy_score: 0.736\n",
      "precision_score: 0.205\n",
      "recall_score: 0.182\n",
      "\n",
      "confusion_matrix: \n",
      "\n",
      "[[99  8]\n",
      " [34 18]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model(XGBClassifier(), xtrain_tfidf_ngram.tocsc(), xvalid_tfidf_ngram.tocsc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(xtrain_tfidf_ngram,train_y)\n",
    "predict_y = m.predict(xvalid_tfidf_ngram)\n",
    "predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67     1\n",
       "349    1\n",
       "272    0\n",
       "124    0\n",
       "276    0\n",
       "504    0\n",
       "702    0\n",
       "84     1\n",
       "467    0\n",
       "642    0\n",
       "664    0\n",
       "468    1\n",
       "701    0\n",
       "214    0\n",
       "248    0\n",
       "65     0\n",
       "418    1\n",
       "503    1\n",
       "422    0\n",
       "669    0\n",
       "169    0\n",
       "713    0\n",
       "719    0\n",
       "154    1\n",
       "611    0\n",
       "357    1\n",
       "339    1\n",
       "30     1\n",
       "285    0\n",
       "66     0\n",
       "      ..\n",
       "476    1\n",
       "204    0\n",
       "290    1\n",
       "26     0\n",
       "353    0\n",
       "510    0\n",
       "792    0\n",
       "382    1\n",
       "343    0\n",
       "409    1\n",
       "208    0\n",
       "520    0\n",
       "660    0\n",
       "633    0\n",
       "482    0\n",
       "111    1\n",
       "206    0\n",
       "419    0\n",
       "484    0\n",
       "480    0\n",
       "372    1\n",
       "630    0\n",
       "471    0\n",
       "605    0\n",
       "256    0\n",
       "48     0\n",
       "515    1\n",
       "668    1\n",
       "609    0\n",
       "329    1\n",
       "Name: churn_likeliness, Length: 159, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                      56991\n",
       "carrier                                                   att tmobile\n",
       "sentiment                                                         neg\n",
       "polarity                                                    -0.195238\n",
       "churn_likeliness                                                    1\n",
       "clf_text            @att @tmobile smart move leaving @att just get...\n",
       "Name: 349, dtype: object"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[349]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
